{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DTW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DatainSociety/test/blob/master/DTW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEIxiyTJi_zD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f851925-d875-4c8f-e89e-ff00cba07a1c"
      },
      "source": [
        "!pip install sparkmagic\n",
        "!pip install pyspark\n",
        "# !pip install tensorflow\n",
        "from functools import reduce\n",
        "from pyspark import StorageLevel\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from datetime import datetime, timedelta\n",
        "from pyspark.sql import Window, Row, DataFrame\n",
        "\n",
        "from pyspark.sql.types import StringType, FloatType\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "#from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, MinMaxScaler\n",
        "from itertools import chain\n",
        "# generate random floating point values\n",
        "from random import seed, random, randint, uniform\n",
        "import pandas as pd\n",
        "\n",
        "# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "# tf.config.experimental_connect_to_cluster(tpu)\n",
        "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\n",
        "# # instantiate a distribution strategy\n",
        "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "#CREATE SPARK SESSION\n",
        "\n",
        "def UnionAll(dfs):\n",
        "    data = reduce(DataFrame.unionAll,dfs)\n",
        "    return data\n",
        "\n",
        "def create_subsequence_data(feature_data,feature_selection_list,seq_len):\n",
        "    subsequence_dict = {}\n",
        "    smaller_sequence_count=0\n",
        "    raw_total_sequences = 0 \n",
        "    index_reference = 0\n",
        "    step_size = 3\n",
        "    feature_data.sort_values(by=['sequence_id','trade_date'],inplace=True)\n",
        "    for name, chunk in feature_data.groupby(['sequence_id']):\n",
        "        sequence_num = 0\n",
        "        if len(chunk) > seq_len:\n",
        "            i = 0\n",
        "            while i*step_size + seq_len <= len(chunk):\n",
        "                if i==0:\n",
        "                    subsequence_chunk = chunk.iloc[0:i*step_size + seq_len,:]\n",
        "                else:\n",
        "                    subsequence_chunk = chunk.iloc[i*step_size:step_size+seq_len, :]\n",
        "                subsequence_chunk['sequence_id'] = index_reference\n",
        "                subsequence_chunk.sort_values(by=['trade_date'],inplace=True);subsequence_chunk.reset_index(inplace=True)\n",
        "                subsequence_chunk = subsequence_chunk[['trade_date','sequence_id'] + feature_selection_list]\n",
        "                subsequence_dict[index_reference] = subsequence_chunk\n",
        "                sequence_num +=1\n",
        "                index_reference+=1\n",
        "                i+=1\n",
        "            else:\n",
        "                if len(chunk) > 5:\n",
        "                    smaller_sequence_count +=1\n",
        "                    small_chunk = chunk.copy()\n",
        "                    small_chunk['sequence_id'] = index_reference\n",
        "                    small_chunk.sort_values(by=['trade_date'],inplace=True)\n",
        "                    small_chunk = small_chunk[['trade_date','sequence_id',]+feature_selection_list]\n",
        "                    subsequence_dict[index_reference] = small_chunk\n",
        "                    sequence_num +=1\n",
        "                    index_reference+=1\n",
        "            raw_total_sequences+=1\n",
        "        if subsequence_dict:\n",
        "            subsequence_array = pd.concat(subsequence_dict,axis=0)\n",
        "        else:\n",
        "            subsequence_array = pd.DataFrame(columns = ['trade_date','sequence_id'] + [x for x in feature_selection_list])\n",
        "    return subsequence_array\n",
        "\n",
        "def interpolate_subsequence(subsequence_dataset,feature_selection_list,seq_len):\n",
        "    subsequence_dict = {}\n",
        "    subsequence_dataset.drop(['tradeId', 'Date'], axis = 1)\n",
        "    for subsequence_id in subsequence_dataset['sequence_id'].drop_duplicates():\n",
        "        chunk = subsequence_dataset[subsequence_dataset['sequence_id'] == subsequence_id]\n",
        "        if len(chunk) < seq_len:\n",
        "            chunk_interpolated = pd.DataFrame(index = [x for x in range(seq_len)])\n",
        "            chunk_interpolated['sequence_id'] = subsequence_id               \n",
        "            chunk_interpolated['trade_data'] = chunk['trade_date'].drop_duplicates()[0]\n",
        "#             chunk_interpolated['trader'] = chunk['trader'].drop_duplicates()[0]   \n",
        " \n",
        "            #Interpolate all continuous valued variables using a Cubic Hermite Spline\n",
        "            for feature in feature_selection_list: #select all continuous valued variables\n",
        "                original_feature_data = pd.DataFrame(chunk[feature]).reset_index(drop = True)            \n",
        "                #Create the required length df by creating an index the same length as the original data but that is sampled at a higher rate\n",
        "                temp_df = pd.DataFrame(data = {feature:np.nan, 'interpolated_indicator': 1}, index = [(x*(len(chunk)-1)/seq_len) for x in range(seq_len)])\n",
        "                temp_df_concat = pd.concat([original_feature_data, temp_df], axis = 0, sort = True).sort_index(axis = 0)\n",
        "                #Interpolate data points using monotone cubic interpolation -\n",
        "                    #Preserves the shape of the time series, monotonicity ensures that new local minima/maxima are not introduced\n",
        "                temp_df_concat[feature] = temp_df_concat[feature].interpolate(method = 'slinear')\n",
        "                chunk_interpolated[feature] = temp_df_concat[feature][temp_df_concat['interpolated_indicator'] == 1].reset_index(drop = True)  \n",
        "                \n",
        "            subsequence_dict[subsequence_id] = chunk_interpolated\n",
        "        else:\n",
        "            subsequence_dict[subsequence_id] = chunk\n",
        "    if subsequence_dict:       \n",
        "        subsequence_array = pd.concat(subsequence_dict.values(), axis = 0)\n",
        "    else:\n",
        "        subsequence_array = pd.DataFrame(columns  = ['sequence_id', 'trade_date', 'trader'] + feature_selection_list)\n",
        "    return subsequence_array\n",
        " \n",
        "\n",
        "def spark_create_subseq_dataset(feature_data, feature_selection_list, seq_len):\n",
        "    \"\"\"Generates a dataframe by subseq_id with sequences of data.\n",
        "    These are to be converted to numpy arrays and then dumped into \n",
        "    multivariate dtw algo.\"\"\"\n",
        "    \n",
        "    subsequence_dict={}\n",
        "    smaller_seq_count=0\n",
        "    raw_total_sequences=0\n",
        "    index_reference=0\n",
        "    #Number to increment data by\n",
        "    step_size=3\n",
        "    #Create list of subseq_ids to filter by \n",
        "    print(\"starting sequencing\")\n",
        "    sids = [i[0] for i in spark.sql(\"SELECT DISTINCT sequence_id FROM ScaledTable\").collect()]\n",
        "    feature_data = feature_data.withColumn('id',monotonically_increasing_id())\n",
        "    feature_data.createOrReplaceTempView('ST')\n",
        "    #Filter to dataset required, using SQL -> Catalyst engine more efficient\n",
        "    for sid in sids:\n",
        "        sequence_num=0\n",
        "        sql_query = \"SELECT * FROM ST WHERE sequence_id=\"+\"'\"+str(sid)+\"'\"\n",
        "#         feature_data = feature_data.filter(col('sequence_id')=sid) \n",
        "        chunk = spark.sql(sql_query)\n",
        "        chunk.createOrReplaceTempView(\"subseq\")\n",
        "        print(\"created subseq table\")\n",
        "        if chunk.count()>seq_len:\n",
        "            i=0\n",
        "            while i*step_size + seq_len <= chunk.count():\n",
        "                if i==0:\n",
        "                    step_query=\"SELECT * FROM subseq WHERE id BETWEEN \"+\"'0'\"+\"AND \"+\"'\"+str((i*step_size)+seq_len)+\"'\"\n",
        "                    subsequence_chunk = spark.sql(step_query)\n",
        "                    print(\"creating first sequence...\")\n",
        "                else:\n",
        "                    step_query=\"SELECT * FROM subseq WHERE id BETWEEN \"+\"'\"+str(i)+\"'\"+\"AND\"+\"'\"+str((i*step_size)+seq_len)+\"'\"\n",
        "                    print(f\"creating sequence number: {i}\")\n",
        "                subsequence_chunk = spark.sql(step_query)\n",
        "                subsequence_chunk = subsequence_chunk.withColumn('subsequence_id',lit(index_reference))\n",
        "                subsequence_chunk=subsequence_chunk.orderBy('trade_date')\n",
        "                cols = ['trade_date','subsequence_id']+feature_selection_list\n",
        "                subsequence_chunk = subsequence_chunk.select(cols)\n",
        "                subsequence_dict[index_reference]=subsequence_chunk\n",
        "                sequence_num+=1\n",
        "                index_reference+=1\n",
        "                i+=1\n",
        "        else:\n",
        "            if chunk.count()>5:\n",
        "                print(\"sequence is smaller so create small seq\")\n",
        "                smaller_sequence_count+=1\n",
        "                small_chunk = chunk\n",
        "                small_chunk.withColumn('sub_subsequence_id',lit(index_reference))\n",
        "                small_chunk.orderBy('trade_date')\n",
        "                s_cols = ['trade_date','sub_subsequence_id']+feature_selection_list\n",
        "                small_chunk = small_chunk.select(s_cols)\n",
        "                subsequence_dict[index_reference] = small_chunk\n",
        "                sequence_num +=1\n",
        "                index_reference+=1\n",
        "            raw_total_sequences+=1\n",
        "    if subsequence_dict:\n",
        "        subsequence_array = pd.concat(subsequence_dict,axis=0)\n",
        "    else:\n",
        "        subsequence_array = pd.DataFrame(columns = ['trade_date','sequence_id'] + [x for x in feature_selection_list])\n",
        "    return subsequence_dict\n",
        "\n",
        "\n",
        "# df = spark.read.csv('/kaggle/input/forex-eurusd-dataset/dataset01_eurusd4h.csv', inferSchema=True,header=True)\n",
        "\n",
        "#Write this data to kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sparkmagic\n",
            "  Downloading https://files.pythonhosted.org/packages/09/d4/468941ef9a48c35c7a870d868996e84f89ad0ef9178f46abcba111a25fad/sparkmagic-0.17.0.tar.gz\n",
            "Collecting hdijupyterutils>=0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/eb/4afdfdfcc1c53b2fec43126b13cf4e41a8ab60d80995626a75b8a94787a2/hdijupyterutils-0.17.0.tar.gz\n",
            "Collecting autovizwidget>=0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/1b/2b/ca743774da5ac18061dac161c252e2021a02dd0aec26ea388e96be0d66d7/autovizwidget-0.17.0.tar.gz\n",
            "Requirement already satisfied: ipython>=4.0.2 in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (5.5.0)\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 4.9MB/s \n",
            "\u001b[?25hCollecting mock\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (1.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (2.23.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (4.10.1)\n",
            "Requirement already satisfied: ipywidgets>5.0.0 in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (7.5.1)\n",
            "Requirement already satisfied: notebook>=4.2 in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (5.3.1)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (5.1.1)\n",
            "Collecting requests_kerberos>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/a2/866f2b9a60f75055137b9ad127033e397963b2c4769d4b5fab1c3c7e8be3/requests_kerberos-0.12.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: jupyter>=1 in /usr/local/lib/python3.6/dist-packages (from hdijupyterutils>=0.6->sparkmagic) (1.0.0)\n",
            "Requirement already satisfied: plotly>=3 in /usr/local/lib/python3.6/dist-packages (from autovizwidget>=0.6->sparkmagic) (4.4.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (50.3.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (4.3.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (4.4.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.1->sparkmagic) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.1->sparkmagic) (2.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->sparkmagic) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->sparkmagic) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->sparkmagic) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->sparkmagic) (2020.6.20)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->sparkmagic) (5.3.5)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>5.0.0->sparkmagic) (5.0.8)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>5.0.0->sparkmagic) (3.5.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook>=4.2->sparkmagic) (0.2.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.2->sparkmagic) (0.9.1)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.2->sparkmagic) (4.6.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.2->sparkmagic) (1.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.2->sparkmagic) (2.11.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.2->sparkmagic) (5.6.1)\n",
            "Collecting cryptography>=1.3; python_version != \"3.3\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/a2/6565c5271a79e3c96d7a079053b4d8408a740d4bf365f0f5f244a807bd09/cryptography-3.2.1-cp35-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 9.7MB/s \n",
            "\u001b[?25hCollecting pykerberos<2.0.0,>=1.1.8; sys_platform != \"win32\"\n",
            "  Downloading https://files.pythonhosted.org/packages/9a/b8/1ec56b6fa8a2e2a81420bd3d90e70b59fc83f6b857fb2c2c37accddc8be3/pykerberos-1.2.1.tar.gz\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter>=1->hdijupyterutils>=0.6->sparkmagic) (4.7.7)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter>=1->hdijupyterutils>=0.6->sparkmagic) (5.2.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=3->autovizwidget>=0.6->sparkmagic) (1.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly>=3->autovizwidget>=0.6->sparkmagic) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.2->sparkmagic) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.2->sparkmagic) (0.2.5)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->sparkmagic) (19.0.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>5.0.0->sparkmagic) (2.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook>=4.2->sparkmagic) (1.1.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.2->sparkmagic) (0.4.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.2->sparkmagic) (1.4.3)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.2->sparkmagic) (0.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.2->sparkmagic) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.2->sparkmagic) (3.2.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.2->sparkmagic) (0.8.4)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=1.3; python_version != \"3.3\"->requests_kerberos>=0.8.0->sparkmagic) (1.14.3)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter>=1->hdijupyterutils>=0.6->sparkmagic) (1.9.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.2->sparkmagic) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.2->sparkmagic) (20.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=1.3; python_version != \"3.3\"->requests_kerberos>=0.8.0->sparkmagic) (2.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert->notebook>=4.2->sparkmagic) (2.4.7)\n",
            "Building wheels for collected packages: sparkmagic, hdijupyterutils, autovizwidget, pykerberos\n",
            "  Building wheel for sparkmagic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sparkmagic: filename=sparkmagic-0.17.0-cp36-none-any.whl size=60491 sha256=d16d1203f7f5a3efc1791353e90c3f8bbf0a0ae7217d0cd4f097150c929e6ad3\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/1f/22/903630ee7b72f853124d540babb1e7f48654cdc99b36b6eb2c\n",
            "  Building wheel for hdijupyterutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdijupyterutils: filename=hdijupyterutils-0.17.0-cp36-none-any.whl size=7698 sha256=21cd6ed7648ee59912657832045527aac1fb79d55dd2af0189e160a676620b51\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/49/d1/996ce2579dcc2822b037e4c7425fec834495360ad65266922f\n",
            "  Building wheel for autovizwidget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autovizwidget: filename=autovizwidget-0.17.0-cp36-none-any.whl size=14547 sha256=2d5047f67bfc1b491f5cd9f254123423dd86277b007e63d71e1d7b8aca9e3c7f\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/ac/4e/d40a9affa9544e2beb1f7a0d714500610f3d38277a60210912\n",
            "  Building wheel for pykerberos (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pykerberos\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for pykerberos\n",
            "Successfully built sparkmagic hdijupyterutils autovizwidget\n",
            "Failed to build pykerberos\n",
            "Installing collected packages: nose, mock, hdijupyterutils, autovizwidget, cryptography, pykerberos, requests-kerberos, sparkmagic\n",
            "    Running setup.py install for pykerberos ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-rx4a_nm9/pykerberos/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-rx4a_nm9/pykerberos/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-3v_v1yok/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n",
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/26/198fc8c0b98580f617cb03cb298c6056587b8f0447e20fa40c5b634ced77/pyspark-3.0.1.tar.gz (204.2MB)\n",
            "\u001b[K     |████████████████████████████████| 204.2MB 56kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 43.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.1-py2.py3-none-any.whl size=204612243 sha256=dd7f5385649a0b4ec16357929e950019450c74315acc8cc3daca9861d94910a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/bd/07/031766ca628adec8435bb40f0bd83bb676ce65ff4007f8e73f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geGqKFh-jERd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f4edf57-64e9-4c04-99d4-57d8db38a5db"
      },
      "source": [
        "import string\n",
        "import random\n",
        "#Create random_string for tradeId\n",
        "def str_gen(length):\n",
        "    stringlist=[]\n",
        "    num = []\n",
        "    letters = string.ascii_letters\n",
        "    for i in range(length):\n",
        "        stringlist.append(random.choice(letters))\n",
        "        num.append(str(randint(0,9)))\n",
        "    word = ''.join(stringlist)\n",
        "    num = ''.join(num)\n",
        "    word = word+'-'+num[:2]\n",
        "    return word\n",
        "\n",
        "s_dt = datetime(2020, 10, 1)-timedelta(hours=17912)\n",
        "end_dt = datetime(2020,10,1)\n",
        "step = timedelta(seconds=randint(30,150))\n",
        "dts = []\n",
        "while s_dt<=end_dt:\n",
        "    dts.append(s_dt.strftime('%Y-%m-%d %H:%M:%S'))\n",
        "    s_dt+=step\n",
        "# volume = [randint(1000,10000000) for num in range(df.count())]\n",
        "#Seed the number for random generator\n",
        "seed(1)\n",
        "#Generate example dataset\n",
        "base_dict = {}\n",
        "for num in range(1,len(dts)):\n",
        "    base_dict[num] = {'participation_rate':random.random(),\n",
        "                      'Date':dts[num],\n",
        "                      'Volume':randint(1000,10000000)*(randint(0,9)+randint(0,9)),\n",
        "                     'Strike':uniform(0.9875,1.12345),\n",
        "                     'tradeId': str_gen(7)\n",
        "                     }\n",
        "    if num % 10000==0:\n",
        "        print(f\"{num} rows created\")\n",
        "    else:\n",
        "        continue\n",
        "    \n",
        "data_as_rows = [Row(**{'row_id': k, **v}) for k,v in base_dict.items()]\n",
        "\n",
        "from pyspark.sql.types import StructType, StructField, StringType\n",
        "#Define schema to prevent ValueError\n",
        "# schema = StructType([StructField(\"foo\", StringType(), True), StructFie])\n",
        "schema = 'row_id INTEGER, participation_rate STRING, Date STRING, Volume INTEGER, Strike DOUBLE, tradeId STRING'\n",
        "b = spark.createDataFrame(data_as_rows,schema=schema)\n",
        "# b.to_csv('testdata.csv')\n",
        "# b = spark.read.csv('./testdata.csv/*.csv',header=True)\n",
        "#Create monotonically increasing ids\n",
        "# df = df.withColumn('row_id',row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
        "# Join dfs\n",
        "b = b.withColumn('CCYPAIR',lit('EURUSD'))\n",
        "b = b.withColumn('trade_date',to_date(col('Date')))\n",
        "#Create window\n",
        "#Then denserank, we are assuming working with one traders worth of data\n",
        "subspec = Window.partitionBy('CCYPAIR').orderBy('trade_date')\n",
        "b = b.withColumn('sequence_id',dense_rank().over(subspec))\n",
        "#Scale dataset\n",
        "features = b.columns\n",
        "assemblers = [VectorAssembler(inputCols=[col], outputCol=col+\"_vec\") for col in features]\n",
        "scalers = [MinMaxScaler(inputCol=col+\"_vec\",outputCol=col+\"_scaled\") for col in features]\n",
        "#Convert all columns to float\n",
        "float_df = b.select(*(col(c).cast(\"float\").alias(c) for c in b.columns)).fillna(0)\n",
        "\n",
        "pipeline = Pipeline(stages=assemblers+scalers)\n",
        "model = pipeline.fit(float_df)\n",
        "scaled_df =model.transform(float_df)\n",
        "#Only select scaled columns\n",
        "scaledData = scaled_df.select([col for col in scaled_df.columns if '_scaled' in col])\n",
        "first_element=udf((lambda x:x[0]),FloatType())\n",
        "scaledData=scaledData.select([first_element(col) for col in scaledData.columns])\n",
        "#Rename columns\n",
        "r_scaled_df = reduce(lambda scaledData,idx: scaledData.withColumnRenamed(scaledData.columns[idx],features[idx]),range(len(scaledData.columns)),float_df)\n",
        "\n",
        "#Merge datasets to bring back non float data\n",
        "drop_cols = ['Date','trade_date','CCYPAIR']\n",
        "#Drop string cols\n",
        "r_scaled_df = reduce(DataFrame.drop,drop_cols,r_scaled_df)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000 rows created\n",
            "20000 rows created\n",
            "30000 rows created\n",
            "40000 rows created\n",
            "50000 rows created\n",
            "60000 rows created\n",
            "70000 rows created\n",
            "80000 rows created\n",
            "90000 rows created\n",
            "100000 rows created\n",
            "110000 rows created\n",
            "120000 rows created\n",
            "130000 rows created\n",
            "140000 rows created\n",
            "150000 rows created\n",
            "160000 rows created\n",
            "170000 rows created\n",
            "180000 rows created\n",
            "190000 rows created\n",
            "200000 rows created\n",
            "210000 rows created\n",
            "220000 rows created\n",
            "230000 rows created\n",
            "240000 rows created\n",
            "250000 rows created\n",
            "260000 rows created\n",
            "270000 rows created\n",
            "280000 rows created\n",
            "290000 rows created\n",
            "300000 rows created\n",
            "310000 rows created\n",
            "320000 rows created\n",
            "330000 rows created\n",
            "340000 rows created\n",
            "350000 rows created\n",
            "360000 rows created\n",
            "370000 rows created\n",
            "380000 rows created\n",
            "390000 rows created\n",
            "400000 rows created\n",
            "410000 rows created\n",
            "420000 rows created\n",
            "430000 rows created\n",
            "440000 rows created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT7unMICjJ5F"
      },
      "source": [
        "def interpolate_subsequence(subsequence_dataset,feature_selection_list,seq_len):\n",
        "    subsequence_dict = {}\n",
        "    subsequence_dataset.drop(['tradeId', 'Date'], axis = 1)\n",
        "    for subsequence_id in subsequence_dataset['sequence_id'].drop_duplicates():\n",
        "        chunk = subsequence_dataset[subsequence_dataset['sequence_id'] == subsequence_id]\n",
        "        if len(chunk) < seq_len:\n",
        "            chunk_interpolated = pd.DataFrame(index = [x for x in range(seq_len)])\n",
        "            chunk_interpolated['sequence_id'] = subsequence_id               \n",
        "            chunk_interpolated['trade_date'] = chunk['trade_date'].drop_duplicates()\n",
        "#             chunk_interpolated['trader'] = chunk['trader'].drop_duplicates()[0]   \n",
        " \n",
        "            #Interpolate all continuous valued variables using a Cubic Hermite Spline\n",
        "            for feature in feature_selection_list: #select all continuous valued variables\n",
        "                original_feature_data = pd.DataFrame(chunk[feature]).reset_index(drop = True)            \n",
        "                #Create the required length df by creating an index the same length as the original data but that is sampled at a higher rate\n",
        "                temp_df = pd.DataFrame(data = {feature:np.nan, 'interpolated_indicator': 1}, index = [(x*(len(chunk)-1)/seq_len) for x in range(seq_len)])\n",
        "                temp_df_concat = pd.concat([original_feature_data, temp_df], axis = 0, sort = True).sort_index(axis = 0)\n",
        "                #Interpolate data points using monotone cubic interpolation -\n",
        "                    #Preserves the shape of the time series, monotonicity ensures that new local minima/maxima are not introduced\n",
        "                temp_df_concat[feature] = temp_df_concat[feature].interpolate(method = 'slinear')\n",
        "                chunk_interpolated[feature] = temp_df_concat[feature][temp_df_concat['interpolated_indicator'] == 1].reset_index(drop = True)  \n",
        "                \n",
        "            subsequence_dict[subsequence_id] = chunk_interpolated\n",
        "        else:\n",
        "            subsequence_dict[subsequence_id] = chunk\n",
        "    if subsequence_dict:       \n",
        "        subsequence_array = pd.concat(subsequence_dict.values(), axis = 0)\n",
        "    else:\n",
        "        subsequence_array = pd.DataFrame(columns  = ['sequence_id', 'trade_date', 'trader'] + feature_selection_list)\n",
        "    return subsequence_array\n",
        "\n",
        "final_df = r_scaled_df.join(b.select('row_id','CCYPAIR','trade_date','Date','tradeId'),'row_id',how='inner').drop(r_scaled_df.tradeId)\n",
        "#Run subsequencing on scaled_Df\n",
        "#Generate subsequence data\n",
        "subseq_window = Window.partitionBy('sequence_id').orderBy('row_id')\n",
        "final_df = final_df.withColumn('subseq_id',dense_rank().over(subseq_window))\n",
        "p_df = final_df.toPandas()\n",
        "#Interpolate data\n",
        "interp_df = interpolate_subsequence(p_df,features,100)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o05H9jebjMzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "549b9b90-1a14-43c0-eafc-bb5a57738f05"
      },
      "source": [
        "#Installing dependencies for Rpy2\n",
        "import subprocess\n",
        "subprocess.run('conda install -c conda-forge r-base', shell=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args='conda install -c conda-forge r-base', returncode=127)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy-DQ5ydjQOL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52bd9ee5-93a6-4edd-94e7-8a5e22c6309d"
      },
      "source": [
        "# using numba to speed up function\n",
        "# from numba import jit\n",
        "!pip3 install rpy2\n",
        "!pip install tslearn\n",
        "# os.environ\n",
        "import time\n",
        "def trade_dict_gen(df):\n",
        "    start_time = time.perf_counter()\n",
        "    trade_dict = {}\n",
        "    #Filter to sequence_id\n",
        "    ids = [i for i in df['sequence_id'].drop_duplicates()]\n",
        "    #Drop all data and only keep continuous variables\n",
        "    cont_df = df.drop(columns=['row_id','CCYPAIR','trade_date','Date','tradeId','subseq_id'])\n",
        "    for i in ids:\n",
        "        #Converts df into numpy array\n",
        "        trade_dict[i] = cont_df[cont_df.sequence_id == i].values\n",
        "    print(f\"Time elapsed is {time.perf_counter() - start_time}\")\n",
        "    return trade_dict\n",
        "\n",
        "trade_dict = trade_dict_gen(interp_df)\n",
        "\n",
        "# !python -m rpy2.situation\n",
        "import numpy as np\n",
        "import rpy2.robjects as robjects\n",
        "import rpy2.robjects.numpy2ri\n",
        "rpy2.robjects.numpy2ri.activate()\n",
        "from rpy2.robjects.packages import importr\n",
        "utils = robjects.packages.importr(\"utils\")\n",
        "package_name = \"dtw\"\n",
        "utils.install_packages(package_name)\n",
        "\n",
        "R = robjects.r\n",
        "\n",
        "DTW = importr('dtw')\n",
        "\n",
        "def DTW(s1,s2,window):\n",
        "    R = rpy2.robjects.r\n",
        "    DTW = importr('dtw')\n",
        "    R.dtw = SignatureTranslatedFunction(R.dtw,\n",
        "                        init_prm_translate={'window_size': 'window.size'})\n",
        "    rt,ct=s1.shape\n",
        "    rq,cq = s2.shape\n",
        "    templateR=R.matrix(s1,nrow=rt,ncol=ct)\n",
        "    queryR=R.matrix(s2,nrow=rq,ncol=cq)\n",
        "    alignment = R.dtw(templateR,queryR,keep=True, step_pattern=R.rabinerJuangStepPattern(4,\"c\"),open_begin=True,open_end=True)\n",
        "    dist = alignment.rx('distance')[0][0]\n",
        "    return dist\n",
        "\n",
        "from tslearn import metrics\n",
        "# from numba import jit\n",
        "# @jit\n",
        "def compute_manipulation_scoresv2(t_dict):\n",
        "#     for each series compare to all other series then average it\n",
        "    \n",
        "    #create a list of all other \n",
        "    #Compare to all other sequences\n",
        "    seq_ids = [i for i in t_dict.keys()]\n",
        "    print('Function started')\n",
        "    start_time = time.perf_counter()\n",
        "    for num in range(1,len(t_dict)):\n",
        "        print(f\"Comparing sequence number: {num}\")\n",
        "        df_list=[seq for seq in seq_ids]\n",
        "        del df_list[num]\n",
        "        for idx in df_list:\n",
        "            dtw_dists = []\n",
        "            dtw_dists.append(metrics.dtw(t_dict[num],t_dict[idx]))\n",
        "            t_dict[num]=np.mean(dtw_dists)\n",
        "    print(f\"Time elapsed is {time.perf_counter() - start_time}\")\n",
        "    return t_dict\n",
        "\n",
        "dist_scores = compute_manipulation_scoresv2(trade_dict)\n",
        "\n",
        "# Map values to dataframe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rpy2 in /usr/local/lib/python3.6/dist-packages (3.2.7)\n",
            "Requirement already satisfied: simplegeneric in /usr/local/lib/python3.6/dist-packages (from rpy2) (0.8.1)\n",
            "Requirement already satisfied: cffi>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from rpy2) (1.14.3)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.6/dist-packages (from rpy2) (1.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from rpy2) (2.11.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from rpy2) (3.6.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from rpy2) (2018.9)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.13.1->rpy2) (2.20)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->rpy2) (1.1.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->rpy2) (1.15.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->rpy2) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->rpy2) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->rpy2) (8.6.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->rpy2) (1.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->rpy2) (50.3.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->rpy2) (20.2.0)\n",
            "Collecting tslearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/67/aa3149fdfef2582d881ce4a5117c9e6a465d5082dd57866904ca508a157c/tslearn-0.4.1-cp36-cp36m-manylinux2010_x86_64.whl (770kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from tslearn) (0.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from tslearn) (0.22.2.post1)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from tslearn) (0.29.21)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tslearn) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from tslearn) (1.4.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from tslearn) (0.48.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->tslearn) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->tslearn) (50.3.2)\n",
            "Installing collected packages: tslearn\n",
            "Successfully installed tslearn-0.4.1\n",
            "Time elapsed is 1.3175112900000272\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "R[write to console]: Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "R[write to console]: also installing the dependency ‘proxy’\n",
            "\n",
            "\n",
            "R[write to console]: trying URL 'https://cran.rstudio.com/src/contrib/proxy_0.4-24.tar.gz'\n",
            "\n",
            "R[write to console]: Content type 'application/x-gzip'\n",
            "R[write to console]:  length 115932 bytes (113 KB)\n",
            "\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: \n",
            "\n",
            "R[write to console]: downloaded 113 KB\n",
            "\n",
            "\n",
            "R[write to console]: trying URL 'https://cran.rstudio.com/src/contrib/dtw_1.22-3.tar.gz'\n",
            "\n",
            "R[write to console]: Content type 'application/x-gzip'\n",
            "R[write to console]:  length 882684 bytes (861 KB)\n",
            "\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: \n",
            "\n",
            "R[write to console]: downloaded 861 KB\n",
            "\n",
            "\n",
            "R[write to console]: \n",
            "\n",
            "R[write to console]: \n",
            "R[write to console]: The downloaded source packages are in\n",
            "\t‘/tmp/RtmpccrBf4/downloaded_packages’\n",
            "R[write to console]: \n",
            "R[write to console]: \n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Function started\n",
            "Comparing sequence number: 1\n",
            "Comparing sequence number: 2\n",
            "Comparing sequence number: 3\n",
            "Comparing sequence number: 4\n",
            "Comparing sequence number: 5\n",
            "Comparing sequence number: 6\n",
            "Comparing sequence number: 7\n",
            "Comparing sequence number: 8\n",
            "Comparing sequence number: 9\n",
            "Comparing sequence number: 10\n",
            "Comparing sequence number: 11\n",
            "Comparing sequence number: 12\n",
            "Comparing sequence number: 13\n",
            "Comparing sequence number: 14\n",
            "Comparing sequence number: 15\n",
            "Comparing sequence number: 16\n",
            "Comparing sequence number: 17\n",
            "Comparing sequence number: 18\n",
            "Comparing sequence number: 19\n",
            "Comparing sequence number: 20\n",
            "Comparing sequence number: 21\n",
            "Comparing sequence number: 22\n",
            "Comparing sequence number: 23\n",
            "Comparing sequence number: 24\n",
            "Comparing sequence number: 25\n",
            "Comparing sequence number: 26\n",
            "Comparing sequence number: 27\n",
            "Comparing sequence number: 28\n",
            "Comparing sequence number: 29\n",
            "Comparing sequence number: 30\n",
            "Comparing sequence number: 31\n",
            "Comparing sequence number: 32\n",
            "Comparing sequence number: 33\n",
            "Comparing sequence number: 34\n",
            "Comparing sequence number: 35\n",
            "Comparing sequence number: 36\n",
            "Comparing sequence number: 37\n",
            "Comparing sequence number: 38\n",
            "Comparing sequence number: 39\n",
            "Comparing sequence number: 40\n",
            "Comparing sequence number: 41\n",
            "Comparing sequence number: 42\n",
            "Comparing sequence number: 43\n",
            "Comparing sequence number: 44\n",
            "Comparing sequence number: 45\n",
            "Comparing sequence number: 46\n",
            "Comparing sequence number: 47\n",
            "Comparing sequence number: 48\n",
            "Comparing sequence number: 49\n",
            "Comparing sequence number: 50\n",
            "Comparing sequence number: 51\n",
            "Comparing sequence number: 52\n",
            "Comparing sequence number: 53\n",
            "Comparing sequence number: 54\n",
            "Comparing sequence number: 55\n",
            "Comparing sequence number: 56\n",
            "Comparing sequence number: 57\n",
            "Comparing sequence number: 58\n",
            "Comparing sequence number: 59\n",
            "Comparing sequence number: 60\n",
            "Comparing sequence number: 61\n",
            "Comparing sequence number: 62\n",
            "Comparing sequence number: 63\n",
            "Comparing sequence number: 64\n",
            "Comparing sequence number: 65\n",
            "Comparing sequence number: 66\n",
            "Comparing sequence number: 67\n",
            "Comparing sequence number: 68\n",
            "Comparing sequence number: 69\n",
            "Comparing sequence number: 70\n",
            "Comparing sequence number: 71\n",
            "Comparing sequence number: 72\n",
            "Comparing sequence number: 73\n",
            "Comparing sequence number: 74\n",
            "Comparing sequence number: 75\n",
            "Comparing sequence number: 76\n",
            "Comparing sequence number: 77\n",
            "Comparing sequence number: 78\n",
            "Comparing sequence number: 79\n",
            "Comparing sequence number: 80\n",
            "Comparing sequence number: 81\n",
            "Comparing sequence number: 82\n",
            "Comparing sequence number: 83\n",
            "Comparing sequence number: 84\n",
            "Comparing sequence number: 85\n",
            "Comparing sequence number: 86\n",
            "Comparing sequence number: 87\n",
            "Comparing sequence number: 88\n",
            "Comparing sequence number: 89\n",
            "Comparing sequence number: 90\n",
            "Comparing sequence number: 91\n",
            "Comparing sequence number: 92\n",
            "Comparing sequence number: 93\n",
            "Comparing sequence number: 94\n",
            "Comparing sequence number: 95\n",
            "Comparing sequence number: 96\n",
            "Comparing sequence number: 97\n",
            "Comparing sequence number: 98\n",
            "Comparing sequence number: 99\n",
            "Comparing sequence number: 100\n",
            "Comparing sequence number: 101\n",
            "Comparing sequence number: 102\n",
            "Comparing sequence number: 103\n",
            "Comparing sequence number: 104\n",
            "Comparing sequence number: 105\n",
            "Comparing sequence number: 106\n",
            "Comparing sequence number: 107\n",
            "Comparing sequence number: 108\n",
            "Comparing sequence number: 109\n",
            "Comparing sequence number: 110\n",
            "Comparing sequence number: 111\n",
            "Comparing sequence number: 112\n",
            "Comparing sequence number: 113\n",
            "Comparing sequence number: 114\n",
            "Comparing sequence number: 115\n",
            "Comparing sequence number: 116\n",
            "Comparing sequence number: 117\n",
            "Comparing sequence number: 118\n",
            "Comparing sequence number: 119\n",
            "Comparing sequence number: 120\n",
            "Comparing sequence number: 121\n",
            "Comparing sequence number: 122\n",
            "Comparing sequence number: 123\n",
            "Comparing sequence number: 124\n",
            "Comparing sequence number: 125\n",
            "Comparing sequence number: 126\n",
            "Comparing sequence number: 127\n",
            "Comparing sequence number: 128\n",
            "Comparing sequence number: 129\n",
            "Comparing sequence number: 130\n",
            "Comparing sequence number: 131\n",
            "Comparing sequence number: 132\n",
            "Comparing sequence number: 133\n",
            "Comparing sequence number: 134\n",
            "Comparing sequence number: 135\n",
            "Comparing sequence number: 136\n",
            "Comparing sequence number: 137\n",
            "Comparing sequence number: 138\n",
            "Comparing sequence number: 139\n",
            "Comparing sequence number: 140\n",
            "Comparing sequence number: 141\n",
            "Comparing sequence number: 142\n",
            "Comparing sequence number: 143\n",
            "Comparing sequence number: 144\n",
            "Comparing sequence number: 145\n",
            "Comparing sequence number: 146\n",
            "Comparing sequence number: 147\n",
            "Comparing sequence number: 148\n",
            "Comparing sequence number: 149\n",
            "Comparing sequence number: 150\n",
            "Comparing sequence number: 151\n",
            "Comparing sequence number: 152\n",
            "Comparing sequence number: 153\n",
            "Comparing sequence number: 154\n",
            "Comparing sequence number: 155\n",
            "Comparing sequence number: 156\n",
            "Comparing sequence number: 157\n",
            "Comparing sequence number: 158\n",
            "Comparing sequence number: 159\n",
            "Comparing sequence number: 160\n",
            "Comparing sequence number: 161\n",
            "Comparing sequence number: 162\n",
            "Comparing sequence number: 163\n",
            "Comparing sequence number: 164\n",
            "Comparing sequence number: 165\n",
            "Comparing sequence number: 166\n",
            "Comparing sequence number: 167\n",
            "Comparing sequence number: 168\n",
            "Comparing sequence number: 169\n",
            "Comparing sequence number: 170\n",
            "Comparing sequence number: 171\n",
            "Comparing sequence number: 172\n",
            "Comparing sequence number: 173\n",
            "Comparing sequence number: 174\n",
            "Comparing sequence number: 175\n",
            "Comparing sequence number: 176\n",
            "Comparing sequence number: 177\n",
            "Comparing sequence number: 178\n",
            "Comparing sequence number: 179\n",
            "Comparing sequence number: 180\n",
            "Comparing sequence number: 181\n",
            "Comparing sequence number: 182\n",
            "Comparing sequence number: 183\n",
            "Comparing sequence number: 184\n",
            "Comparing sequence number: 185\n",
            "Comparing sequence number: 186\n",
            "Comparing sequence number: 187\n",
            "Comparing sequence number: 188\n",
            "Comparing sequence number: 189\n",
            "Comparing sequence number: 190\n",
            "Comparing sequence number: 191\n",
            "Comparing sequence number: 192\n",
            "Comparing sequence number: 193\n",
            "Comparing sequence number: 194\n",
            "Comparing sequence number: 195\n",
            "Comparing sequence number: 196\n",
            "Comparing sequence number: 197\n",
            "Comparing sequence number: 198\n",
            "Comparing sequence number: 199\n",
            "Comparing sequence number: 200\n",
            "Comparing sequence number: 201\n",
            "Comparing sequence number: 202\n",
            "Comparing sequence number: 203\n",
            "Comparing sequence number: 204\n",
            "Comparing sequence number: 205\n",
            "Comparing sequence number: 206\n",
            "Comparing sequence number: 207\n",
            "Comparing sequence number: 208\n",
            "Comparing sequence number: 209\n",
            "Comparing sequence number: 210\n",
            "Comparing sequence number: 211\n",
            "Comparing sequence number: 212\n",
            "Comparing sequence number: 213\n",
            "Comparing sequence number: 214\n",
            "Comparing sequence number: 215\n",
            "Comparing sequence number: 216\n",
            "Comparing sequence number: 217\n",
            "Comparing sequence number: 218\n",
            "Comparing sequence number: 219\n",
            "Comparing sequence number: 220\n",
            "Comparing sequence number: 221\n",
            "Comparing sequence number: 222\n",
            "Comparing sequence number: 223\n",
            "Comparing sequence number: 224\n",
            "Comparing sequence number: 225\n",
            "Comparing sequence number: 226\n",
            "Comparing sequence number: 227\n",
            "Comparing sequence number: 228\n",
            "Comparing sequence number: 229\n",
            "Comparing sequence number: 230\n",
            "Comparing sequence number: 231\n",
            "Comparing sequence number: 232\n",
            "Comparing sequence number: 233\n",
            "Comparing sequence number: 234\n",
            "Comparing sequence number: 235\n",
            "Comparing sequence number: 236\n",
            "Comparing sequence number: 237\n",
            "Comparing sequence number: 238\n",
            "Comparing sequence number: 239\n",
            "Comparing sequence number: 240\n",
            "Comparing sequence number: 241\n",
            "Comparing sequence number: 242\n",
            "Comparing sequence number: 243\n",
            "Comparing sequence number: 244\n",
            "Comparing sequence number: 245\n",
            "Comparing sequence number: 246\n",
            "Comparing sequence number: 247\n",
            "Comparing sequence number: 248\n",
            "Comparing sequence number: 249\n",
            "Comparing sequence number: 250\n",
            "Comparing sequence number: 251\n",
            "Comparing sequence number: 252\n",
            "Comparing sequence number: 253\n",
            "Comparing sequence number: 254\n",
            "Comparing sequence number: 255\n",
            "Comparing sequence number: 256\n",
            "Comparing sequence number: 257\n",
            "Comparing sequence number: 258\n",
            "Comparing sequence number: 259\n",
            "Comparing sequence number: 260\n",
            "Comparing sequence number: 261\n",
            "Comparing sequence number: 262\n",
            "Comparing sequence number: 263\n",
            "Comparing sequence number: 264\n",
            "Comparing sequence number: 265\n",
            "Comparing sequence number: 266\n",
            "Comparing sequence number: 267\n",
            "Comparing sequence number: 268\n",
            "Comparing sequence number: 269\n",
            "Comparing sequence number: 270\n",
            "Comparing sequence number: 271\n",
            "Comparing sequence number: 272\n",
            "Comparing sequence number: 273\n",
            "Comparing sequence number: 274\n",
            "Comparing sequence number: 275\n",
            "Comparing sequence number: 276\n",
            "Comparing sequence number: 277\n",
            "Comparing sequence number: 278\n",
            "Comparing sequence number: 279\n",
            "Comparing sequence number: 280\n",
            "Comparing sequence number: 281\n",
            "Comparing sequence number: 282\n",
            "Comparing sequence number: 283\n",
            "Comparing sequence number: 284\n",
            "Comparing sequence number: 285\n",
            "Comparing sequence number: 286\n",
            "Comparing sequence number: 287\n",
            "Comparing sequence number: 288\n",
            "Comparing sequence number: 289\n",
            "Comparing sequence number: 290\n",
            "Comparing sequence number: 291\n",
            "Comparing sequence number: 292\n",
            "Comparing sequence number: 293\n",
            "Comparing sequence number: 294\n",
            "Comparing sequence number: 295\n",
            "Comparing sequence number: 296\n",
            "Comparing sequence number: 297\n",
            "Comparing sequence number: 298\n",
            "Comparing sequence number: 299\n",
            "Comparing sequence number: 300\n",
            "Comparing sequence number: 301\n",
            "Comparing sequence number: 302\n",
            "Comparing sequence number: 303\n",
            "Comparing sequence number: 304\n",
            "Comparing sequence number: 305\n",
            "Comparing sequence number: 306\n",
            "Comparing sequence number: 307\n",
            "Comparing sequence number: 308\n",
            "Comparing sequence number: 309\n",
            "Comparing sequence number: 310\n",
            "Comparing sequence number: 311\n",
            "Comparing sequence number: 312\n",
            "Comparing sequence number: 313\n",
            "Comparing sequence number: 314\n",
            "Comparing sequence number: 315\n",
            "Comparing sequence number: 316\n",
            "Comparing sequence number: 317\n",
            "Comparing sequence number: 318\n",
            "Comparing sequence number: 319\n",
            "Comparing sequence number: 320\n",
            "Comparing sequence number: 321\n",
            "Comparing sequence number: 322\n",
            "Comparing sequence number: 323\n",
            "Comparing sequence number: 324\n",
            "Comparing sequence number: 325\n",
            "Comparing sequence number: 326\n",
            "Comparing sequence number: 327\n",
            "Comparing sequence number: 328\n",
            "Comparing sequence number: 329\n",
            "Comparing sequence number: 330\n",
            "Comparing sequence number: 331\n",
            "Comparing sequence number: 332\n",
            "Comparing sequence number: 333\n",
            "Comparing sequence number: 334\n",
            "Comparing sequence number: 335\n",
            "Comparing sequence number: 336\n",
            "Comparing sequence number: 337\n",
            "Comparing sequence number: 338\n",
            "Comparing sequence number: 339\n",
            "Comparing sequence number: 340\n",
            "Comparing sequence number: 341\n",
            "Comparing sequence number: 342\n",
            "Comparing sequence number: 343\n",
            "Comparing sequence number: 344\n",
            "Comparing sequence number: 345\n",
            "Comparing sequence number: 346\n",
            "Comparing sequence number: 347\n",
            "Comparing sequence number: 348\n",
            "Comparing sequence number: 349\n",
            "Comparing sequence number: 350\n",
            "Comparing sequence number: 351\n",
            "Comparing sequence number: 352\n",
            "Comparing sequence number: 353\n",
            "Comparing sequence number: 354\n",
            "Comparing sequence number: 355\n",
            "Comparing sequence number: 356\n",
            "Comparing sequence number: 357\n",
            "Comparing sequence number: 358\n",
            "Comparing sequence number: 359\n",
            "Comparing sequence number: 360\n",
            "Comparing sequence number: 361\n",
            "Comparing sequence number: 362\n",
            "Comparing sequence number: 363\n",
            "Comparing sequence number: 364\n",
            "Comparing sequence number: 365\n",
            "Comparing sequence number: 366\n",
            "Comparing sequence number: 367\n",
            "Comparing sequence number: 368\n",
            "Comparing sequence number: 369\n",
            "Comparing sequence number: 370\n",
            "Comparing sequence number: 371\n",
            "Comparing sequence number: 372\n",
            "Comparing sequence number: 373\n",
            "Comparing sequence number: 374\n",
            "Comparing sequence number: 375\n",
            "Comparing sequence number: 376\n",
            "Comparing sequence number: 377\n",
            "Comparing sequence number: 378\n",
            "Comparing sequence number: 379\n",
            "Comparing sequence number: 380\n",
            "Comparing sequence number: 381\n",
            "Comparing sequence number: 382\n",
            "Comparing sequence number: 383\n",
            "Comparing sequence number: 384\n",
            "Comparing sequence number: 385\n",
            "Comparing sequence number: 386\n",
            "Comparing sequence number: 387\n",
            "Comparing sequence number: 388\n",
            "Comparing sequence number: 389\n",
            "Comparing sequence number: 390\n",
            "Comparing sequence number: 391\n",
            "Comparing sequence number: 392\n",
            "Comparing sequence number: 393\n",
            "Comparing sequence number: 394\n",
            "Comparing sequence number: 395\n",
            "Comparing sequence number: 396\n",
            "Comparing sequence number: 397\n",
            "Comparing sequence number: 398\n",
            "Comparing sequence number: 399\n",
            "Comparing sequence number: 400\n",
            "Comparing sequence number: 401\n",
            "Comparing sequence number: 402\n",
            "Comparing sequence number: 403\n",
            "Comparing sequence number: 404\n",
            "Comparing sequence number: 405\n",
            "Comparing sequence number: 406\n",
            "Comparing sequence number: 407\n",
            "Comparing sequence number: 408\n",
            "Comparing sequence number: 409\n",
            "Comparing sequence number: 410\n",
            "Comparing sequence number: 411\n",
            "Comparing sequence number: 412\n",
            "Comparing sequence number: 413\n",
            "Comparing sequence number: 414\n",
            "Comparing sequence number: 415\n",
            "Comparing sequence number: 416\n",
            "Comparing sequence number: 417\n",
            "Comparing sequence number: 418\n",
            "Comparing sequence number: 419\n",
            "Comparing sequence number: 420\n",
            "Comparing sequence number: 421\n",
            "Comparing sequence number: 422\n",
            "Comparing sequence number: 423\n",
            "Comparing sequence number: 424\n",
            "Comparing sequence number: 425\n",
            "Comparing sequence number: 426\n",
            "Comparing sequence number: 427\n",
            "Comparing sequence number: 428\n",
            "Comparing sequence number: 429\n",
            "Comparing sequence number: 430\n",
            "Comparing sequence number: 431\n",
            "Comparing sequence number: 432\n",
            "Comparing sequence number: 433\n",
            "Comparing sequence number: 434\n",
            "Comparing sequence number: 435\n",
            "Comparing sequence number: 436\n",
            "Comparing sequence number: 437\n",
            "Comparing sequence number: 438\n",
            "Comparing sequence number: 439\n",
            "Comparing sequence number: 440\n",
            "Comparing sequence number: 441\n",
            "Comparing sequence number: 442\n",
            "Comparing sequence number: 443\n",
            "Comparing sequence number: 444\n",
            "Comparing sequence number: 445\n",
            "Comparing sequence number: 446\n",
            "Comparing sequence number: 447\n",
            "Comparing sequence number: 448\n",
            "Comparing sequence number: 449\n",
            "Comparing sequence number: 450\n",
            "Comparing sequence number: 451\n",
            "Comparing sequence number: 452\n",
            "Comparing sequence number: 453\n",
            "Comparing sequence number: 454\n",
            "Comparing sequence number: 455\n",
            "Comparing sequence number: 456\n",
            "Comparing sequence number: 457\n",
            "Comparing sequence number: 458\n",
            "Comparing sequence number: 459\n",
            "Comparing sequence number: 460\n",
            "Comparing sequence number: 461\n",
            "Comparing sequence number: 462\n",
            "Comparing sequence number: 463\n",
            "Comparing sequence number: 464\n",
            "Comparing sequence number: 465\n",
            "Comparing sequence number: 466\n",
            "Comparing sequence number: 467\n",
            "Comparing sequence number: 468\n",
            "Comparing sequence number: 469\n",
            "Comparing sequence number: 470\n",
            "Comparing sequence number: 471\n",
            "Comparing sequence number: 472\n",
            "Comparing sequence number: 473\n",
            "Comparing sequence number: 474\n",
            "Comparing sequence number: 475\n",
            "Comparing sequence number: 476\n",
            "Comparing sequence number: 477\n",
            "Comparing sequence number: 478\n",
            "Comparing sequence number: 479\n",
            "Comparing sequence number: 480\n",
            "Comparing sequence number: 481\n",
            "Comparing sequence number: 482\n",
            "Comparing sequence number: 483\n",
            "Comparing sequence number: 484\n",
            "Comparing sequence number: 485\n",
            "Comparing sequence number: 486\n",
            "Comparing sequence number: 487\n",
            "Comparing sequence number: 488\n",
            "Comparing sequence number: 489\n",
            "Comparing sequence number: 490\n",
            "Comparing sequence number: 491\n",
            "Comparing sequence number: 492\n",
            "Comparing sequence number: 493\n",
            "Comparing sequence number: 494\n",
            "Comparing sequence number: 495\n",
            "Comparing sequence number: 496\n",
            "Comparing sequence number: 497\n",
            "Comparing sequence number: 498\n",
            "Comparing sequence number: 499\n",
            "Comparing sequence number: 500\n",
            "Comparing sequence number: 501\n",
            "Comparing sequence number: 502\n",
            "Comparing sequence number: 503\n",
            "Comparing sequence number: 504\n",
            "Comparing sequence number: 505\n",
            "Comparing sequence number: 506\n",
            "Comparing sequence number: 507\n",
            "Comparing sequence number: 508\n",
            "Comparing sequence number: 509\n",
            "Comparing sequence number: 510\n",
            "Comparing sequence number: 511\n",
            "Comparing sequence number: 512\n",
            "Comparing sequence number: 513\n",
            "Comparing sequence number: 514\n",
            "Comparing sequence number: 515\n",
            "Comparing sequence number: 516\n",
            "Comparing sequence number: 517\n",
            "Comparing sequence number: 518\n",
            "Comparing sequence number: 519\n",
            "Comparing sequence number: 520\n",
            "Comparing sequence number: 521\n",
            "Comparing sequence number: 522\n",
            "Comparing sequence number: 523\n",
            "Comparing sequence number: 524\n",
            "Comparing sequence number: 525\n",
            "Comparing sequence number: 526\n",
            "Comparing sequence number: 527\n",
            "Comparing sequence number: 528\n",
            "Comparing sequence number: 529\n",
            "Comparing sequence number: 530\n",
            "Comparing sequence number: 531\n",
            "Comparing sequence number: 532\n",
            "Comparing sequence number: 533\n",
            "Comparing sequence number: 534\n",
            "Comparing sequence number: 535\n",
            "Comparing sequence number: 536\n",
            "Comparing sequence number: 537\n",
            "Comparing sequence number: 538\n",
            "Comparing sequence number: 539\n",
            "Comparing sequence number: 540\n",
            "Comparing sequence number: 541\n",
            "Comparing sequence number: 542\n",
            "Comparing sequence number: 543\n",
            "Comparing sequence number: 544\n",
            "Comparing sequence number: 545\n",
            "Comparing sequence number: 546\n",
            "Comparing sequence number: 547\n",
            "Comparing sequence number: 548\n",
            "Comparing sequence number: 549\n",
            "Comparing sequence number: 550\n",
            "Comparing sequence number: 551\n",
            "Comparing sequence number: 552\n",
            "Comparing sequence number: 553\n",
            "Comparing sequence number: 554\n",
            "Comparing sequence number: 555\n",
            "Comparing sequence number: 556\n",
            "Comparing sequence number: 557\n",
            "Comparing sequence number: 558\n",
            "Comparing sequence number: 559\n",
            "Comparing sequence number: 560\n",
            "Comparing sequence number: 561\n",
            "Comparing sequence number: 562\n",
            "Comparing sequence number: 563\n",
            "Comparing sequence number: 564\n",
            "Comparing sequence number: 565\n",
            "Comparing sequence number: 566\n",
            "Comparing sequence number: 567\n",
            "Comparing sequence number: 568\n",
            "Comparing sequence number: 569\n",
            "Comparing sequence number: 570\n",
            "Comparing sequence number: 571\n",
            "Comparing sequence number: 572\n",
            "Comparing sequence number: 573\n",
            "Comparing sequence number: 574\n",
            "Comparing sequence number: 575\n",
            "Comparing sequence number: 576\n",
            "Comparing sequence number: 577\n",
            "Comparing sequence number: 578\n",
            "Comparing sequence number: 579\n",
            "Comparing sequence number: 580\n",
            "Comparing sequence number: 581\n",
            "Comparing sequence number: 582\n",
            "Comparing sequence number: 583\n",
            "Comparing sequence number: 584\n",
            "Comparing sequence number: 585\n",
            "Comparing sequence number: 586\n",
            "Comparing sequence number: 587\n",
            "Comparing sequence number: 588\n",
            "Comparing sequence number: 589\n",
            "Comparing sequence number: 590\n",
            "Comparing sequence number: 591\n",
            "Comparing sequence number: 592\n",
            "Comparing sequence number: 593\n",
            "Comparing sequence number: 594\n",
            "Comparing sequence number: 595\n",
            "Comparing sequence number: 596\n",
            "Comparing sequence number: 597\n",
            "Comparing sequence number: 598\n",
            "Comparing sequence number: 599\n",
            "Comparing sequence number: 600\n",
            "Comparing sequence number: 601\n",
            "Comparing sequence number: 602\n",
            "Comparing sequence number: 603\n",
            "Comparing sequence number: 604\n",
            "Comparing sequence number: 605\n",
            "Comparing sequence number: 606\n",
            "Comparing sequence number: 607\n",
            "Comparing sequence number: 608\n",
            "Comparing sequence number: 609\n",
            "Comparing sequence number: 610\n",
            "Comparing sequence number: 611\n",
            "Comparing sequence number: 612\n",
            "Comparing sequence number: 613\n",
            "Comparing sequence number: 614\n",
            "Comparing sequence number: 615\n",
            "Comparing sequence number: 616\n",
            "Comparing sequence number: 617\n",
            "Comparing sequence number: 618\n",
            "Comparing sequence number: 619\n",
            "Comparing sequence number: 620\n",
            "Comparing sequence number: 621\n",
            "Comparing sequence number: 622\n",
            "Comparing sequence number: 623\n",
            "Comparing sequence number: 624\n",
            "Comparing sequence number: 625\n",
            "Comparing sequence number: 626\n",
            "Comparing sequence number: 627\n",
            "Comparing sequence number: 628\n",
            "Comparing sequence number: 629\n",
            "Comparing sequence number: 630\n",
            "Comparing sequence number: 631\n",
            "Comparing sequence number: 632\n",
            "Comparing sequence number: 633\n",
            "Comparing sequence number: 634\n",
            "Comparing sequence number: 635\n",
            "Comparing sequence number: 636\n",
            "Comparing sequence number: 637\n",
            "Comparing sequence number: 638\n",
            "Comparing sequence number: 639\n",
            "Comparing sequence number: 640\n",
            "Comparing sequence number: 641\n",
            "Comparing sequence number: 642\n",
            "Comparing sequence number: 643\n",
            "Comparing sequence number: 644\n",
            "Comparing sequence number: 645\n",
            "Comparing sequence number: 646\n",
            "Comparing sequence number: 647\n",
            "Comparing sequence number: 648\n",
            "Comparing sequence number: 649\n",
            "Comparing sequence number: 650\n",
            "Comparing sequence number: 651\n",
            "Comparing sequence number: 652\n",
            "Comparing sequence number: 653\n",
            "Comparing sequence number: 654\n",
            "Comparing sequence number: 655\n",
            "Comparing sequence number: 656\n",
            "Comparing sequence number: 657\n",
            "Comparing sequence number: 658\n",
            "Comparing sequence number: 659\n",
            "Comparing sequence number: 660\n",
            "Comparing sequence number: 661\n",
            "Comparing sequence number: 662\n",
            "Comparing sequence number: 663\n",
            "Comparing sequence number: 664\n",
            "Comparing sequence number: 665\n",
            "Comparing sequence number: 666\n",
            "Comparing sequence number: 667\n",
            "Comparing sequence number: 668\n",
            "Comparing sequence number: 669\n",
            "Comparing sequence number: 670\n",
            "Comparing sequence number: 671\n",
            "Comparing sequence number: 672\n",
            "Comparing sequence number: 673\n",
            "Comparing sequence number: 674\n",
            "Comparing sequence number: 675\n",
            "Comparing sequence number: 676\n",
            "Comparing sequence number: 677\n",
            "Comparing sequence number: 678\n",
            "Comparing sequence number: 679\n",
            "Comparing sequence number: 680\n",
            "Comparing sequence number: 681\n",
            "Comparing sequence number: 682\n",
            "Comparing sequence number: 683\n",
            "Comparing sequence number: 684\n",
            "Comparing sequence number: 685\n",
            "Comparing sequence number: 686\n",
            "Comparing sequence number: 687\n",
            "Comparing sequence number: 688\n",
            "Comparing sequence number: 689\n",
            "Comparing sequence number: 690\n",
            "Comparing sequence number: 691\n",
            "Comparing sequence number: 692\n",
            "Comparing sequence number: 693\n",
            "Comparing sequence number: 694\n",
            "Comparing sequence number: 695\n",
            "Comparing sequence number: 696\n",
            "Comparing sequence number: 697\n",
            "Comparing sequence number: 698\n",
            "Comparing sequence number: 699\n",
            "Comparing sequence number: 700\n",
            "Comparing sequence number: 701\n",
            "Comparing sequence number: 702\n",
            "Comparing sequence number: 703\n",
            "Comparing sequence number: 704\n",
            "Comparing sequence number: 705\n",
            "Comparing sequence number: 706\n",
            "Comparing sequence number: 707\n",
            "Comparing sequence number: 708\n",
            "Comparing sequence number: 709\n",
            "Comparing sequence number: 710\n",
            "Comparing sequence number: 711\n",
            "Comparing sequence number: 712\n",
            "Comparing sequence number: 713\n",
            "Comparing sequence number: 714\n",
            "Comparing sequence number: 715\n",
            "Comparing sequence number: 716\n",
            "Comparing sequence number: 717\n",
            "Comparing sequence number: 718\n",
            "Comparing sequence number: 719\n",
            "Comparing sequence number: 720\n",
            "Comparing sequence number: 721\n",
            "Comparing sequence number: 722\n",
            "Comparing sequence number: 723\n",
            "Comparing sequence number: 724\n",
            "Comparing sequence number: 725\n",
            "Comparing sequence number: 726\n",
            "Comparing sequence number: 727\n",
            "Comparing sequence number: 728\n",
            "Comparing sequence number: 729\n",
            "Comparing sequence number: 730\n",
            "Comparing sequence number: 731\n",
            "Comparing sequence number: 732\n",
            "Comparing sequence number: 733\n",
            "Comparing sequence number: 734\n",
            "Comparing sequence number: 735\n",
            "Comparing sequence number: 736\n",
            "Comparing sequence number: 737\n",
            "Comparing sequence number: 738\n",
            "Comparing sequence number: 739\n",
            "Comparing sequence number: 740\n",
            "Comparing sequence number: 741\n",
            "Comparing sequence number: 742\n",
            "Comparing sequence number: 743\n",
            "Comparing sequence number: 744\n",
            "Comparing sequence number: 745\n",
            "Comparing sequence number: 746\n",
            "Time elapsed is 39.535433452999996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc5lvcrQjUF8"
      },
      "source": [
        "dist_scorev2 = {}\n",
        "# if infinity then remove\n",
        "\n",
        "for k,v in dist_scores.items():\n",
        "    dist_scorev2[k] = np.mean(v)\n",
        "    if dist_scorev2[k] > 1E308: \n",
        "        del dist_scorev2[k]\n",
        "    else:\n",
        "        continue \n",
        "\n",
        "#Plot data on histogram\n",
        "# import matplotlib.pyplot as plt\n",
        "# dist_vals = dist_scores.values()\n",
        "# interp_df = interp_df.replace([np.inf, -np.inf],np.nan)\n",
        "\n",
        "# plt.hist(dist_scores.values())\n",
        "# dist_scores.values().dropna()\n",
        "dist_scores = dist_scorev2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sb8ZofcjWdP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c09c3b00-7403-4848-8313-91214205a50c"
      },
      "source": [
        "interp_df['dist_scores'] = interp_df['row_id'].map(dist_scores)\n",
        "display(dist_scores)\n",
        "interp_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{13.0: 326.2995735197645,\n",
              " 28.0: 1.6042574310684763e+105,\n",
              " 37.0: 8.374221875737821e+46,\n",
              " 60.0: 1.2619348610690474e+94,\n",
              " 61.0: 1.2619348610690474e+94,\n",
              " 74.0: 4659012.097830499,\n",
              " 75.0: 6.098214223282816e+17,\n",
              " 111.0: 2.1173403709211906e+91,\n",
              " 114.0: 6.743612981069505e+146,\n",
              " 125.0: 6.743612981069505e+146,\n",
              " 131.0: 6.743612981069505e+146,\n",
              " 135.0: 6.743612981069505e+146,\n",
              " 153.0: 14.352191348376829,\n",
              " 155.0: 2.7622915068593546e+145,\n",
              " 184.0: 2.7286695279739906e+34,\n",
              " 208.0: 7.276884221650112e+53,\n",
              " 212.0: 1.4551953175013842e+87,\n",
              " 213.0: 1017346529681881.8,\n",
              " 218.0: 1.940617705164745e+73,\n",
              " 237.0: 3.185325428481723e+138,\n",
              " 252.0: 1.5941995504834003e+105,\n",
              " 280.0: 1.9053949144445088e+141,\n",
              " 297.0: 1.9053949144445088e+141,\n",
              " 323.0: 1.1158419530274029e+33,\n",
              " 334.0: 38905428678645.04,\n",
              " 338.0: 3.256069975108627e+70,\n",
              " 352.0: 65103254851.82624,\n",
              " 373.0: 1.3337382295263114e+69,\n",
              " 401.0: 2.1973493803891645e+134,\n",
              " 433.0: 3.431480700469133e+45,\n",
              " 443.0: 9.000693764737608e+132,\n",
              " 502.0: 3.550878643338005e+88,\n",
              " 508.0: 3.550878643338005e+88,\n",
              " 539.0: 166.59020855784797,\n",
              " 541.0: 5.654231798069613e+92,\n",
              " 568.0: 2.5338649623705966e+127,\n",
              " 575.0: 0.0,\n",
              " 587.0: 2655628724.755832,\n",
              " 612.0: 9.486966104143744e+89,\n",
              " 613.0: 2767356415.958723,\n",
              " 626.0: 2771813501.058606,\n",
              " 633.0: 1.5917728362657078e+87,\n",
              " 634.0: 1.2168716859902954e+51,\n",
              " 635.0: 2.576213400139997e+59,\n",
              " 660.0: 6.870271830707214e+78,\n",
              " 669.0: 8.225746046699166e+114,\n",
              " 672.0: 2.576213400139997e+59,\n",
              " 673.0: 298.1119841860874,\n",
              " 674.0: 5.842297549241983e+153,\n",
              " 675.0: 5.842297549241983e+153,\n",
              " 676.0: 5.842297549241983e+153,\n",
              " 677.0: 5.842297549241983e+153,\n",
              " 678.0: 5.842297549241983e+153,\n",
              " 679.0: 5.842297549241983e+153,\n",
              " 680.0: 5.842297549241983e+153,\n",
              " 682.0: 5.842297549241983e+153,\n",
              " 683.0: 1.938988985954034e+73,\n",
              " 684.0: 2.393098320754584e+152,\n",
              " 685.0: 113633498.14504807,\n",
              " 686.0: 9.802512666513308e+150,\n",
              " 688.0: 9.802512666513308e+150,\n",
              " 689.0: 9.802512666513308e+150,\n",
              " 690.0: 9.802512666513308e+150,\n",
              " 691.0: 9.802512666513308e+150,\n",
              " 692.0: 9.802512666513308e+150,\n",
              " 693.0: 9.802512666513308e+150,\n",
              " 695.0: 311.9473821713877,\n",
              " 700.0: 4.018638858597726e+149,\n",
              " 701.0: 4.018915634169222e+149,\n",
              " 704.0: 4.0186383951261557e+149,\n",
              " 705.0: 4.725400692223008e+74,\n",
              " 706.0: 4657894.796490715,\n",
              " 707.0: 6.742681871019149e+146,\n",
              " 710.0: 2.761910109321049e+145,\n",
              " 717.0: 6.742681871016956e+146,\n",
              " 720.0: 6.742681871016956e+146,\n",
              " 722.0: 6.742681871016956e+146,\n",
              " 723.0: 6.742681871016956e+146,\n",
              " 724.0: 6.742681871016956e+146,\n",
              " 725.0: 6.742681871016956e+146,\n",
              " 727.0: 6.742681871016956e+146,\n",
              " 734.0: 6.742681871016956e+146,\n",
              " 736.0: 1.5941995504828338e+105,\n",
              " 737.0: 2.761910109321049e+145,\n",
              " 740.0: 2.761910109321049e+145,\n",
              " 741.0: 2.761910109321049e+145,\n",
              " 743.0: 2.761910109321049e+145,\n",
              " 746.0: 2.761910109321049e+145,\n",
              " 747.0: 10677308.0}"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>participation_rate</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Strike</th>\n",
              "      <th>sequence_id</th>\n",
              "      <th>CCYPAIR</th>\n",
              "      <th>trade_date</th>\n",
              "      <th>Date</th>\n",
              "      <th>tradeId</th>\n",
              "      <th>subseq_id</th>\n",
              "      <th>dist_scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>424453.0</td>\n",
              "      <td>0.275216</td>\n",
              "      <td>907718.0</td>\n",
              "      <td>1.079587</td>\n",
              "      <td>714.0</td>\n",
              "      <td>EURUSD</td>\n",
              "      <td>2020-08-28</td>\n",
              "      <td>2020-08-28 00:01:25</td>\n",
              "      <td>nwfOErP-04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>424454.0</td>\n",
              "      <td>0.799262</td>\n",
              "      <td>23841916.0</td>\n",
              "      <td>1.110936</td>\n",
              "      <td>714.0</td>\n",
              "      <td>EURUSD</td>\n",
              "      <td>2020-08-28</td>\n",
              "      <td>2020-08-28 00:03:50</td>\n",
              "      <td>fDOhkMs-39</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>424455.0</td>\n",
              "      <td>0.021166</td>\n",
              "      <td>35412792.0</td>\n",
              "      <td>1.047110</td>\n",
              "      <td>714.0</td>\n",
              "      <td>EURUSD</td>\n",
              "      <td>2020-08-28</td>\n",
              "      <td>2020-08-28 00:06:15</td>\n",
              "      <td>NtqaiMM-38</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>424456.0</td>\n",
              "      <td>0.233372</td>\n",
              "      <td>23671732.0</td>\n",
              "      <td>0.990246</td>\n",
              "      <td>714.0</td>\n",
              "      <td>EURUSD</td>\n",
              "      <td>2020-08-28</td>\n",
              "      <td>2020-08-28 00:08:40</td>\n",
              "      <td>FgdrGIq-69</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>424457.0</td>\n",
              "      <td>0.339010</td>\n",
              "      <td>60632800.0</td>\n",
              "      <td>1.031385</td>\n",
              "      <td>714.0</td>\n",
              "      <td>EURUSD</td>\n",
              "      <td>2020-08-28</td>\n",
              "      <td>2020-08-28 00:11:05</td>\n",
              "      <td>pXQWVph-56</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     row_id  participation_rate      Volume  ...     tradeId  subseq_id dist_scores\n",
              "0  424453.0            0.275216    907718.0  ...  nwfOErP-04          1         NaN\n",
              "1  424454.0            0.799262  23841916.0  ...  fDOhkMs-39          2         NaN\n",
              "2  424455.0            0.021166  35412792.0  ...  NtqaiMM-38          3         NaN\n",
              "3  424456.0            0.233372  23671732.0  ...  FgdrGIq-69          4         NaN\n",
              "4  424457.0            0.339010  60632800.0  ...  pXQWVph-56          5         NaN\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-ZTPW-ajZuA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "81062e6d-0554-4e66-fb90-591739d5f5d2"
      },
      "source": [
        "# dist_vals[dist_vals < 1E308]\n",
        "# Plot the scores available\n",
        "import plotly.express as px\n",
        "# minds = min(dist_scores.values())\n",
        "# maxds = np.max(np.array(dist_scores.values()))\n",
        "# minds = min(dist_scores.keys(), key=(lambda k: dist_scores[k]))\n",
        "# binnums = (maxds-minds)/len(dist_scores)\n",
        "\n",
        "fig = px.histogram(dist_scores.values(),\n",
        "#                    bins=range(maxds,minds,binnums),\n",
        "                   histnorm='probability',\n",
        "                   title='Histogram of DTW Distances',\n",
        "                   labels={'value':'DTW distances'},\n",
        "                  opacity=0.8,\n",
        "                   log_y=True, # represent bars with log scale\n",
        "                   color_discrete_sequence=['indianred'])\n",
        "fig.show()\n",
        "# dist_scorev2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"baee8dce-90b9-4463-8a07-c98ba14f90dc\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"baee8dce-90b9-4463-8a07-c98ba14f90dc\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'baee8dce-90b9-4463-8a07-c98ba14f90dc',\n",
              "                        [],\n",
              "                        {\"barmode\": \"relative\", \"legend\": {\"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Histogram of DTW Distances\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"count\"}, \"type\": \"log\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('baee8dce-90b9-4463-8a07-c98ba14f90dc');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}